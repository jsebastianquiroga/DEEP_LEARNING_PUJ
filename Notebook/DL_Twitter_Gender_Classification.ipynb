{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m4cmOojch_to",
        "gKiIShYiXv1C",
        "ydlq9_vRaUdQ",
        "yfxtbQ_2ZrWL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/DL_Twitter_User_Gender_Classification/blob/main/Notebook/DL_Twitter_Gender_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img style=\"float: center; padding-right: 10px;\" src=\"https://www.pikpng.com/pngl/b/467-4670553_universidad-javeriana-esslingen-am-neckar-clipart.png\" width=\"100\" height=\"150\">\n",
        "\n",
        "\n",
        "\n",
        "<h1> <strong>Aprendizaje Profundo.</strong></h1> \n",
        "<h2> Para: Ing. Julio Omar Palacio Niño, M.Sc.</br></h2>\n",
        "<h2>Integrantes:</br></h2>\n",
        "<h2>Antonio Jose Caicedo.</br></h2>\n",
        "<h2>Leonardo García.</br></h2>\n",
        "<h2>Juan Sebastián Quiroga Bernal. </h2>"
      ],
      "metadata": {
        "id": "nzIeTlLbgD6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Este colab puede ser ejecutado por cualquier usuario sin necesidad de cargar los archivos al entorno, debido a que la conexión está configurada para acceder a los archivos desde la nube**.\n"
      ],
      "metadata": {
        "id": "C9K1WTgR-UoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <strong>Taller 1: Twitter User Gender Classification.</strong></h1> \n",
        "\n",
        "En el presente Notebook, se exploraran los datos del data set de Kaggel: Twitter User Gender Classification. https://www.kaggle.com/crowdflower/twitter-user-gender-classification/\n",
        "\n",
        "Este conjunto de datos, fue utilziado para entranar un modelo de clasificación de genero conocido como \"CrowdFlower AI\".\n",
        "\n",
        "Cuyo proposito era inferir mendiante el perfil de un usuario de Twitter si el usuario era un hombre, mujer o compañia.\n",
        "\n",
        "Se tienen un total de 20.000 observaciones, conformadas con un nombre de usuario, tuit aleatorio, perfil, la imagen de la cuenta, la ubicación.\n",
        "\n",
        "<ol>\n",
        "_unit_id: un id único para el usuario</ol>\n",
        "<ol>_golden: si el usuario se incluyó en el patrón oro del modelo; TRUE o FALSE</ol>\n",
        "<ol>_unit_state: estado de la observación; uno de finalized (para contributor-judged) o golden (para gold standard observations)</ol>\n",
        "<ol>_trusted_judgments: número de juicios de confianza (int); siempre 3 para las observaciones no gold, y lo que puede ser un identificador único para las observaciones gold standard</ol>\n",
        "<ol>_last_judgment_at: fecha y hora de la última resolución del contribuyente; en blanco para las observaciones gold standard</ol>\n",
        "<ol>gender: uno de masculino, femenino o marca (para perfiles no humanos)</ol>\n",
        "<ol>gender:confidence: valor flotante que representa la confianza en el sexo indicado</ol>\n",
        "<ol>profile_yn: \"no\" aquí parece significar que el perfil debía formar parte del conjunto de datos pero no estaba disponible cuando los colaboradores fueron a juzgarlo</ol>\n",
        "<ol>profile_yn:confidence: confianza en la existencia/no existencia del perfil</ol>\n",
        "<ol>created: fecha y hora de creación del perfil</ol>\n",
        "<ol>description: descripción del perfil del usuario</ol>\n",
        "<ol>fav_number: número de tweets que el usuario ha marcado como favoritos</ol>\n",
        "<ol>gender_gold: si el perfil es dorado, ¿cuál es el género?</ol>\n",
        "<ol>link_color: el color del enlace en el perfil, como valor hexadecimal</ol>\n",
        "<ol>name: nombre del usuario</ol>\n",
        "<ol>profile_yn_gold: si el valor s/n del perfil es dorado</ol>\n",
        "<ol>profileimage: un enlace a la imagen del perfil</ol>\n",
        "<ol>retweet_count: número de veces que el usuario ha retuiteado (o posiblemente, ha sido retuiteado)</ol>\n",
        "<ol>sidebar_color: color de la barra lateral del perfil, como valor hexadecimal</ol>\n",
        "<ol>text: texto de un tweet aleatorio del usuario</ol>\n",
        "<ol>tweet_coord: si el usuario tiene activada la localización, las coordenadas</ol> \n",
        "<ol>como una cadena con el formato \"[latitud, longitud]\"</ol>\n",
        "<ol>tweet_count: número de tweets que ha publicado el usuario</ol>\n",
        "<ol>tweet_created: cuando se creó el tweet aleatorio (en la columna de texto)</ol>\n",
        "<ol>tweet_id: el id del tweet aleatorio</ol>\n",
        "<ol>tweet_location: ubicación del tweet; parece no estar especialmente normalizada</ol>\n",
        "<ol>user_timezone: la zona horaria del usuario</ol>\n",
        "\n",
        "El presente notebook, estará dividido en divido en las siguientes partes:\n",
        "<ol>\n",
        "<li> TBD:. </li>\n",
        "<li> TBD. </li>\n",
        "<li> TBD.</li>\n",
        "</ol>\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "msRcJntlh-dN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <h1><strong> 1. Cargar el data set: </h1></strong>\n",
        "\n",
        "El dataset del link en referencia, fue descargado previamente y subido a google drive, para poder cargar el presente notebook sin problemas al momento de cargar la información. </br>"
      ],
      "metadata": {
        "id": "dpoUbOeVIX9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conexion a gdrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "VPpRP7-bNSgK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "twitter = '1gwF2scW3dpklHez9kNws1tlnSrK0XxWU' \n",
        "\n",
        "\n",
        "download = drive.CreateFile({'id': twitter}) \n",
        "download.GetContentFile('gender-classifier-DFE-791531.csv')"
      ],
      "metadata": {
        "id": "pTU79q0oNYv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LECTURA NODOS Y EDGES FACEBOOK\n",
        "df_tw = pd.read_csv(r'gender-classifier-DFE-791531.csv',encoding=\"latin1\")\n",
        "df_tw.info()\n",
        "df_tw.head()"
      ],
      "metadata": {
        "id": "s4aw8LutLRGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "normalized_gender_counts = df_tw.gender.value_counts(normalize=True)\n",
        "\n",
        "# Using seaborn for the bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "bar_plot = sns.barplot(x=normalized_gender_counts.index, y=normalized_gender_counts.values)\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Normalized Frequency')\n",
        "plt.title('Normalized Gender Distribution')\n",
        "\n",
        "# Add values to the bars\n",
        "for bar in bar_plot.containers[0]:\n",
        "    height = bar.get_height()\n",
        "    bar_plot.annotate(\n",
        "        f'{height:.2%}',\n",
        "        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "        xytext=(0, 3),\n",
        "        textcoords='offset points',\n",
        "        ha='center',\n",
        "        va='bottom',\n",
        "        fontsize=12\n",
        "    )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tj7YQqx7LT53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se encuentra que los tres principales generos estan balanceados, pero se observa un 5,6% de los datos que tiene como genero \"Unkown\"."
      ],
      "metadata": {
        "id": "kcDV121-NB6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tw.isnull().sum()"
      ],
      "metadata": {
        "id": "Tlo7jPsCn-is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='gender',y='retweet_count',data=df_tw)\n",
        "plt.title('Retweet_count by Gender ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jJCAw__-ngL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tw['user_timezone'].unique()\n",
        "df_tw.groupby('user_timezone').size()"
      ],
      "metadata": {
        "id": "bNtMox8kuk1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tw.user_timezone.unique()\n",
        "df_tw.groupby('tweet_created').size()"
      ],
      "metadata": {
        "id": "APQQrOG6yQco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_viaje = df_tw.copy()\n",
        "df_viaje = df_viaje[['created', 'gender']]\n",
        "df_viaje['male'] = np.where(df_viaje.gender=='male',1,0)\n",
        "df_viaje['female'] = np.where(df_viaje.gender=='female',1,0)\n",
        "df_viaje['brand'] = np.where(df_viaje.gender=='brand',1,0)\n",
        "df_viaje['unknown'] = np.where(df_viaje.gender=='unknown',1,0)\n",
        "df_viaje\n",
        "df_d = df_viaje.groupby(['created']).agg(\n",
        "    male = ('male','sum'),\n",
        "    female = ('female','sum'),\n",
        "    brand = ('brand','sum'),\n",
        "    unknown = ('unknown','sum'))\n",
        "df_d\n",
        "# df_d\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(30, 30))\n",
        "fig, ax = plt.subplots()\n",
        "ax = sns.lineplot(data=df_d, linewidth=2.5, palette=['#FA9494', '#140303', '#B46060', '#EA5455'], legend=None, linestyle='solid')\n",
        "for line, name in zip(ax.lines, df_d.columns.tolist()):\n",
        "\ty = line.get_ydata()[-1]\n",
        "\tx = line.get_xdata()[-1]\n",
        "\tif not np.isfinite(y):\n",
        "\t    y=next(reversed(line.get_ydata()[~line.get_ydata().mask]),float(\"nan\"))\n",
        "\tif not np.isfinite(y) or not np.isfinite(x):\n",
        "\t    continue     \n",
        "\ttext = ax.annotate(name,\n",
        "\t\t       xy=(x, y),\n",
        "\t\t       xytext=(0, 0),\n",
        "\t\t       color=line.get_color(),\n",
        "\t\t       xycoords=(ax.get_xaxis_transform(),\n",
        "\t\t\t\t ax.get_yaxis_transform()),\n",
        "\t\t       textcoords=\"offset points\")\n",
        "\ttext_width = (text.get_window_extent(\n",
        "\tfig.canvas.get_renderer()).transformed(ax.transData.inverted()).width)\n",
        "\tif np.isfinite(text_width):\n",
        "\t\tax.set_xlim(ax.get_xlim()[0], text.xy[0] + text_width * 1.05)\n",
        "ax.set(xlabel='created', ylabel='Count', title='created by gender')\n",
        "#ax.legend(title='Type', title_fontsize = 13)\n",
        "sns.despine(bottom=False, left=False)\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "92uoRHy8yYE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = pd.crosstab(df_tw['gender'], [df_tw['_golden']])#, normalize='columns')#, margins=True)\n",
        "# # Plot the crosstab as a bar chart\n",
        "# ax = ct.plot(kind='bar', figsize=(10, 6))\n",
        "# ax.set_xlabel('Gender')\n",
        "# ax.set_ylabel('Frequency')\n",
        "# ax.set_title('Normalized Crosstab')\n",
        "# plt.xticks(rotation=0)  # Rotate x-axis labels\n",
        "\n",
        "# # Add percentage values on top of the bars\n",
        "# for p in ax.patches:\n",
        "#     width, height = p.get_width(), p.get_height()\n",
        "#     x, y = p.get_xy() \n",
        "#     ax.annotate(f'{height:.2}', (x + width / 2, y + height), ha='center', va='bottom')\n",
        "\n",
        "# # Display the plot\n",
        "# plt.show()\n",
        "ct"
      ],
      "metadata": {
        "id": "LFmNC95N9NFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df_tw['gender'], [df_tw['_unit_state']])"
      ],
      "metadata": {
        "id": "CzOUDnN0AMo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(np.where(df_tw._trusted_judgments != 3,0,3)).value_counts(normalize=True)\n"
      ],
      "metadata": {
        "id": "DsKGovs_BE4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_viaje = df_tw.copy()\n",
        "df_viaje = df_viaje[['_last_judgment_at', 'gender']]\n",
        "df_viaje['male'] = np.where(df_viaje.gender=='male',1,0)\n",
        "df_viaje['female'] = np.where(df_viaje.gender=='female',1,0)\n",
        "df_viaje['brand'] = np.where(df_viaje.gender=='brand',1,0)\n",
        "df_viaje['unknown'] = np.where(df_viaje.gender=='unknown',1,0)\n",
        "df_viaje\n",
        "df_d = df_viaje.groupby(['_last_judgment_at']).agg(\n",
        "    male = ('male','sum'),\n",
        "    female = ('female','sum'),\n",
        "    brand = ('brand','sum'),\n",
        "    unknown = ('unknown','sum'))\n",
        "df_d\n",
        "# df_d\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(30, 30))\n",
        "fig, ax = plt.subplots()\n",
        "ax = sns.lineplot(data=df_d, linewidth=2.5, palette=['#FA9494', '#140303', '#B46060', '#EA5455'], legend=None, linestyle='solid')\n",
        "for line, name in zip(ax.lines, df_d.columns.tolist()):\n",
        "\ty = line.get_ydata()[-1]\n",
        "\tx = line.get_xdata()[-1]\n",
        "\tif not np.isfinite(y):\n",
        "\t    y=next(reversed(line.get_ydata()[~line.get_ydata().mask]),float(\"nan\"))\n",
        "\tif not np.isfinite(y) or not np.isfinite(x):\n",
        "\t    continue     \n",
        "\ttext = ax.annotate(name,\n",
        "\t\t       xy=(x, y),\n",
        "\t\t       xytext=(0, 0),\n",
        "\t\t       color=line.get_color(),\n",
        "\t\t       xycoords=(ax.get_xaxis_transform(),\n",
        "\t\t\t\t ax.get_yaxis_transform()),\n",
        "\t\t       textcoords=\"offset points\")\n",
        "\ttext_width = (text.get_window_extent(\n",
        "\tfig.canvas.get_renderer()).transformed(ax.transData.inverted()).width)\n",
        "\tif np.isfinite(text_width):\n",
        "\t\tax.set_xlim(ax.get_xlim()[0], text.xy[0] + text_width * 1.05)\n",
        "ax.set(xlabel='_last_judgment_at', ylabel='Count', title='_last_judgment_at by gender')\n",
        "#ax.legend(title='Type', title_fontsize = 13)\n",
        "sns.despine(bottom=False, left=False)\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wnr59PqFB8Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_viaje = df_tw.copy()\n",
        "df_viaje = df_viaje[['tweet_created', 'gender']]\n",
        "df_viaje['male'] = np.where(df_viaje.gender=='male',1,0)\n",
        "df_viaje['female'] = np.where(df_viaje.gender=='female',1,0)\n",
        "df_viaje['brand'] = np.where(df_viaje.gender=='brand',1,0)\n",
        "df_viaje['unknown'] = np.where(df_viaje.gender=='unknown',1,0)\n",
        "df_viaje\n",
        "df_d = df_viaje.groupby(['tweet_created']).agg(\n",
        "    male = ('male','sum'),\n",
        "    female = ('female','sum'),\n",
        "    brand = ('brand','sum'),\n",
        "    unknown = ('unknown','sum'))\n",
        "df_d\n",
        "# df_d\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(30, 30))\n",
        "fig, ax = plt.subplots()\n",
        "ax = sns.lineplot(data=df_d, linewidth=2.5, palette=['#FA9494', '#140303', '#B46060', '#EA5455'], legend=None, linestyle='solid')\n",
        "for line, name in zip(ax.lines, df_d.columns.tolist()):\n",
        "\ty = line.get_ydata()[-1]\n",
        "\tx = line.get_xdata()[-1]\n",
        "\tif not np.isfinite(y):\n",
        "\t    y=next(reversed(line.get_ydata()[~line.get_ydata().mask]),float(\"nan\"))\n",
        "\tif not np.isfinite(y) or not np.isfinite(x):\n",
        "\t    continue     \n",
        "\ttext = ax.annotate(name,\n",
        "\t\t       xy=(x, y),\n",
        "\t\t       xytext=(0, 0),\n",
        "\t\t       color=line.get_color(),\n",
        "\t\t       xycoords=(ax.get_xaxis_transform(),\n",
        "\t\t\t\t ax.get_yaxis_transform()),\n",
        "\t\t       textcoords=\"offset points\")\n",
        "\ttext_width = (text.get_window_extent(\n",
        "\tfig.canvas.get_renderer()).transformed(ax.transData.inverted()).width)\n",
        "\tif np.isfinite(text_width):\n",
        "\t\tax.set_xlim(ax.get_xlim()[0], text.xy[0] + text_width * 1.05)\n",
        "ax.set(xlabel='tweet_created\t', ylabel='Count', title='tweet_created by gender')\n",
        "#ax.legend(title='Type', title_fontsize = 13)\n",
        "sns.despine(bottom=False, left=False)\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rEgK3f57pDk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bins and labels for the groups\n",
        "bins = [0, 0.25, 0.5, 0.75, 1]\n",
        "labels = ['0-0.25', '0.25-0.5', '0.5-0.75', '0.75-1']\n",
        "\n",
        "# Create a new column 'group' based on the ranges and labels\n",
        "df_tw['group_gender:confidence'] = pd.cut(df_tw['gender:confidence'], bins=bins, labels=labels)\n",
        "\n",
        "\n",
        "# Create a crosstab\n",
        "ct = pd.crosstab(df_tw['gender'], df_tw['group_gender:confidence'])\n",
        "\n",
        "# Plot the crosstab as a bar plot\n",
        "ax = ct.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "plt.title('Gender Distribution by Confidence Group')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Confidence Group', loc='upper right')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hSkYh12SFHv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Outliers\n",
        "sns.boxplot(data=df_tw, x='gender', y='fav_number', showfliers=False)\n",
        "#Add a title and y-axis label\n",
        "plt.title('Boxplot of fav_number based on gender')\n",
        "plt.ylabel('gender_confidence')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9gl-N0lRvIcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bins and labels for the groups\n",
        "bins = [0, 0.25, 0.5, 0.75, 1]\n",
        "labels = ['0-0.25', '0.25-0.5', '0.5-0.75', '0.75-1']\n",
        "\n",
        "# Create a new column 'group' based on the ranges and labels\n",
        "df_tw['group_profile_yn:confidence'] = pd.cut(df_tw['profile_yn:confidence'], bins=bins, labels=labels)\n",
        "\n",
        "\n",
        "# Create a crosstab\n",
        "ct = pd.crosstab(df_tw['gender'], df_tw['group_profile_yn:confidence'])\n",
        "\n",
        "# Plot the crosstab as a bar plot\n",
        "ax = ct.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "plt.title('Gender Distribution by Confidence Group')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Confidence Group', loc='upper right')\n",
        "\n",
        " \n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fi4zELPTIlXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tw.tweet_location.value_counts()"
      ],
      "metadata": {
        "id": "UZKP9uXSKn1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Outliers\n",
        "sns.boxplot(data=df_tw, x='gender', y='retweet_count', showfliers=False)\n",
        "#Add a title and y-axis label\n",
        "plt.title('Boxplot of fav_number based on gender')\n",
        "plt.ylabel('gender_confidence')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XKuNlT7dW3JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a violin plot of Tuition with a hue based on Is.Non.Annual.\n",
        "sns.violinplot(data=df_tw, x='gender', y='gender:confidence')\n",
        "# Add a title and y-axis label\n",
        "plt.title('Violin Plot of gender_confidence based on gender')\n",
        "plt.ylabel('gender_confidence')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-mQdkfQmwJZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tw.columns"
      ],
      "metadata": {
        "id": "CJEppOVSc4a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparación de los datos."
      ],
      "metadata": {
        "id": "H6LUfiVViFi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se removeran las variables '_unit_id', 'tweet_id', '_golden', '_unit_state' '_trusted_judgments', '_last_judgment_at','profile_yn', 'gender_gold', 'profile_yn_gold' las primeras dos por que son un indetificador unico, y no se percibe que por consecusión la de creación sea una variable descriptiva, las restantes por baja representatividad de otros valores.</br>\n",
        "\n",
        "'name' se eliminara para eliminar sezgos por parte de que un nombre defina el genero de una persona.\n",
        "\n",
        "Las variables 'profileimage', 'text','description', debido a que se requiere otro tipo de tratamientos que sale del scope de este ejercicio.\n",
        "\n",
        "Las variables de 'tweet_coord',, 'tweet_location', 'user_timezone', se removeran a su vez para reducir la posible dimencionalidad que se generaria por la futura transformación de datos.\n",
        "\n"
      ],
      "metadata": {
        "id": "n72jfRoddOc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_tw.copy()\n",
        "df = df[df.gender!='unknown']\n",
        "df = df[df.gender.notnull()]\n",
        "\n",
        "df = df[['gender', 'gender:confidence', \n",
        "       'profile_yn:confidence', 'created',  'fav_number','link_color', 'retweet_count', 'sidebar_color', 'tweet_count',\n",
        "       'tweet_created']]\n",
        "df.info()\n",
        "\n",
        "#Se extrae la fecha sin la hora y se transforma en un tipo date time.\n",
        "df.created = df.created.str.split(' ').str[0]\n",
        "df.created = pd.to_datetime(df.created)\n",
        "df['month_created'] = df['created'].dt.month\n",
        "df['day_created'] = df['created'].dt.day\n",
        "df['year_created'] = df['created'].dt.year\n",
        "\n",
        "\n",
        "\n",
        "df.tweet_created = df.tweet_created.str.split(' ').str[0]\n",
        "df.tweet_created = pd.to_datetime(df.tweet_created)\n",
        "df['month_tweet_created'] = df['tweet_created'].dt.month\n",
        "df['day_tweet_created'] = df['tweet_created'].dt.day\n",
        "df['year_tweet_created'] = df['tweet_created'].dt.year\n",
        "df = df.drop(['created', 'tweet_created'], axis=1)\n",
        "\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "ig8uWrJ4c7OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['link_color', 'sidebar_color'], axis=1)\n",
        "df = df.rename(columns={'gender': 'y'})\n",
        "df"
      ],
      "metadata": {
        "id": "0flXEVa9r1_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "beHVv_2Wow9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelamiento."
      ],
      "metadata": {
        "id": "qEfkk1sic2cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = df.copy()\n",
        "X = data.drop('y', axis=1)\n",
        "y = data.y\n",
        "\n",
        "# Scale the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# Print the sizes of the resulting sets\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "9Jgzh47la4lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, num_inputs, num_classes, learning_rate=0.1, max_epochs=100):\n",
        "        self.weights = np.zeros((num_inputs, num_classes))\n",
        "        self.bias = np.zeros(num_classes)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_epochs = max_epochs\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        for epoch in range(self.max_epochs):\n",
        "            for i in range(len(X)):\n",
        "                x = X[i]\n",
        "                z = np.dot(x, self.weights) + self.bias\n",
        "                y_pred = np.argmax(z)\n",
        "                if y_pred != y[i]:\n",
        "                    self.weights[:, y[i]] += self.learning_rate * x\n",
        "                    self.bias[y[i]] += self.learning_rate\n",
        "                    self.weights[:, y_pred] -= self.learning_rate * x\n",
        "                    self.bias[y_pred] -= self.learning_rate\n",
        "                    \n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return np.argmax(z, axis=1)"
      ],
      "metadata": {
        "id": "53fkgif6Xabb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.unique()"
      ],
      "metadata": {
        "id": "vMZ-lmNuv8-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# One-hot encode the target labels\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "y_train_encoded = enc.fit_transform(y_train.to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Train the perceptron\n",
        "perceptron = Perceptron(num_inputs=X_train.shape[1], num_classes=3)\n",
        "perceptron.fit(X_train, np.argmax(y_train_encoded, axis=1))\n",
        "\n",
        "# Predict the class labels for the test set\n",
        "y_test_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Transform y_test_pred back into one-hot encoded format\n",
        "y_test_pred_onehot = np.zeros((y_test_pred.size, y_train_encoded.shape[1]))\n",
        "y_test_pred_onehot[np.arange(y_test_pred.size), y_test_pred] = 1\n",
        "\n",
        "# Decode the predicted labels\n",
        "y_test_pred_decoded = enc.inverse_transform(y_test_pred_onehot)\n",
        "\n",
        "# Compute the accuracy\n",
        "accuracy = np.mean(y_test == y_test_pred_decoded.ravel())\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Compute the classification report\n",
        "report = classification_report(y_test, y_test_pred_decoded, output_dict=True)\n",
        "precision = report['weighted avg']['precision']\n",
        "recall = report['weighted avg']['recall']\n",
        "f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")\n"
      ],
      "metadata": {
        "id": "tF_AWms2aG1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "y_train_encoded = enc.fit_transform(y_train.to_numpy().reshape(-1, 1))\n",
        "y_test_encoded = enc.transform(y_test.to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=X_train.shape[1], activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(units=y_train_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping and model checkpoint callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=200, batch_size=32, validation_split=0.1, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = model.evaluate(X_test, y_test_encoded)\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred_encoded = model.predict(X_test)\n",
        "\n",
        "# Decode the predicted labels\n",
        "y_test_pred_decoded = enc.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Compute the classification report\n",
        "report = classification_report(y_test, y_test_pred_decoded, output_dict=True)\n",
        "precision = report['weighted avg']['precision']\n",
        "recall = report['weighted avg']['recall']\n",
        "f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "\n",
        "print(f\"Test set accuracy: {score[1]}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "id": "RxFAZWFxaHPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=X_train.shape[1]//2, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(units=X_train.shape[1]//2, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=X_train.shape[1]//2, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=y_train_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping and model checkpoint callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=200, batch_size=32, validation_split=0.1, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = model.evaluate(X_test, y_test_encoded)\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred_encoded = model.predict(X_test)\n",
        "\n",
        "# Decode the predicted labels\n",
        "y_test_pred_decoded = enc.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Compute the classification report\n",
        "report = classification_report(y_test, y_test_pred_decoded, output_dict=True)\n",
        "precision = report['weighted avg']['precision']\n",
        "recall = report['weighted avg']['recall']\n",
        "f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print(f\"Test set accuracy: {score[1]}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")\n"
      ],
      "metadata": {
        "id": "eJdxwmecaNbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bono"
      ],
      "metadata": {
        "id": "mAFMf2Wx9uDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bono = df.copy()\n",
        "df_bono['text'] = df['text']\n",
        "df_bono['description'] = df['description']\n",
        "\n",
        "df_bono\n",
        "\n",
        "# agregar nkt"
      ],
      "metadata": {
        "id": "z79Jy2d69u0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}