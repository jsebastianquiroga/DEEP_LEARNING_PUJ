{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/DEEP_LEARNING_PUJ/blob/main/taller_dos/traffic_sign_classification_and_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzIeTlLbgD6s"
   },
   "source": [
    "# <img style=\"float: center; padding-right: 10px;\" src=\"https://www.pikpng.com/pngl/b/467-4670553_universidad-javeriana-esslingen-am-neckar-clipart.png\" width=\"100\" height=\"150\">\n",
    "\n",
    "\n",
    "\n",
    "<h1> <strong>Aprendizaje Profundo.</strong></h1> \n",
    "<h2> Para: Ing. Julio Omar Palacio Niño, M.Sc.</br></h2>\n",
    "<h2>Integrantes:</br></h2>\n",
    "<h2>Antonio Jose Caicedo.</br></h2>\n",
    "<h2>Leonardo García.</br></h2>\n",
    "<h2>Juan Sebastián Quiroga Bernal. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9K1WTgR-UoC"
   },
   "source": [
    "**Este colab puede ser ejecutado por cualquier usuario sin necesidad de cargar los archivos al entorno, debido a que la conexión está configurada para acceder a los archivos desde la nube**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msRcJntlh-dN"
   },
   "source": [
    "<h1> <strong>Taller 2: Traffic Sign Classification and Recognition.</strong></h1> \n",
    "\n",
    "En el presente Notebook, se exploraran los datos del data set de Kaggel: https://www.kaggle.com/datasets/wjybuqi/traffic-sign-classification-and-recognition\n",
    "\n",
    "Este conjunto de datos contiene 6358 etiquetas de categorías etiquetadas manualmente. Las etiquetas incluyen las 10 categorías siguientes: `GuideSign`, `M1`, `M4`, `M5`, `M6`, `M7`, `P1`, `P10_50`, `P12`, `W1`, correspondientes a diez categorías diferentes de señales de tráfico. Todos los datos se han dividido manualmente en conjunto de entrenamiento y conjunto de prueba según la proporción.\n",
    "\n",
    "El presente notebook, estará dividido en divido en las siguientes partes:\n",
    "<ol>\n",
    "<li> TBD:. </li>\n",
    "<li> TBD. </li>\n",
    "<li> TBD.</li>\n",
    "</ol>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f'Number of GPUs available: {len(gpus)}')\n",
    "    for gpu in gpus:\n",
    "        print(f'GPU detected: {gpu}')\n",
    "else:\n",
    "    print('No GPU detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpoUbOeVIX9B"
   },
   "source": [
    "## <h1><strong> 1. Cargar el data set: </h1></strong>\n",
    "\n",
    "El dataset del link en referencia, fue descargado previamente y subido a google drive, para poder cargar el presente notebook sin problemas al momento de cargar la información. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPpRP7-bNSgK"
   },
   "outputs": [],
   "source": [
    "# Conexion a gdrive\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from google.colab import drive\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTU79q0oNYv5"
   },
   "outputs": [],
   "source": [
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "# twitter = '1gwF2scW3dpklHez9kNws1tlnSrK0XxWU' \n",
    "\n",
    "\n",
    "# download = drive.CreateFile({'id': twitter}) \n",
    "# download.GetContentFile('gender-classifier-DFE-791531.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the training and testing dataset folders\n",
    "path_to_folder1 = 'train_dataset/train'\n",
    "path_to_folder2 = 'test_dataset/test'\n",
    "\n",
    "# Function to load image paths and labels from a folder\n",
    "def load_image_paths_and_labels(folder_path):\n",
    "    image_paths = []  # List to store image paths\n",
    "    labels = []       # List to store corresponding labels\n",
    "\n",
    "    # Iterate through each class folder in the given folder_path\n",
    "    for class_index, class_name in enumerate(os.listdir(folder_path)):\n",
    "        # Get all JPEG image file paths in the current class folder\n",
    "        class_image_paths = glob.glob(os.path.join(folder_path, class_name, '*.jpg'))\n",
    "        # Create a list of class indices, one for each image in the current class folder\n",
    "        class_labels = [class_index] * len(class_image_paths)\n",
    "        \n",
    "        # Extend the image_paths and labels lists with the current class's data\n",
    "        image_paths.extend(class_image_paths)\n",
    "        labels.extend(class_labels)\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "# Call the function for both training and testing dataset folders\n",
    "folder1_image_paths, folder1_labels = load_image_paths_and_labels(path_to_folder1)\n",
    "folder2_image_paths, folder2_labels = load_image_paths_and_labels(path_to_folder2)\n",
    "\n",
    "# Combine the image paths and labels from both folders into two larger lists\n",
    "all_image_paths = folder1_image_paths + folder2_image_paths\n",
    "all_labels = folder1_labels + folder2_labels\n",
    "\n",
    "# Print the total number of image paths and labels in the combined lists\n",
    "print(\"Number of image paths:\", len(all_image_paths))\n",
    "print(\"Number of labels:\", len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = train_test_split(all_image_paths, all_labels, test_size=0.2, random_state=42, stratify=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess a single image\n",
    "def load_image(image_path, target_size):\n",
    "    img = load_img(image_path, target_size=target_size, color_mode=\"rgb\")\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target image size (in pixels) and batch size for data processing\n",
    "pixel = 224\n",
    "batch_size = 200\n",
    "num_classes = len(np.unique(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance for the training set with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance for the testing set without data augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the custom data generator for the training and testing sets\n",
    "train_datagen_instance = train_datagen.flow_from_dataframe(dataframe=pd.DataFrame({'image_path': train_image_paths, 'label': [str(label) for label in train_labels]}), directory=None, x_col='image_path', y_col='label', target_size=(pixel, pixel), class_mode='categorical', batch_size=batch_size)\n",
    "test_datagen_instance = test_datagen.flow_from_dataframe(dataframe=pd.DataFrame({'image_path': test_image_paths, 'label': [str(label) for label in test_labels]}), directory=None, x_col='image_path', y_col='label', target_size=(pixel, pixel), class_mode='categorical', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image_paths, labels, title):\n",
    "    indices = np.random.choice(range(len(image_paths)), 10)\n",
    "    selected_image_paths = [image_paths[i] for i in indices]\n",
    "    selected_labels = [labels[i] for i in indices]\n",
    "    \n",
    "    images = np.array([img_to_array(load_img(img_path, target_size=(pixel, pixel))) for img_path in selected_image_paths])\n",
    "    images = images / 255.0\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title(selected_labels[i])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_images(train_image_paths, train_labels, 'Train Images')\n",
    "plot_images(test_image_paths, test_labels, 'Test Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "img_height = pixel\n",
    "img_width = pixel\n",
    "num_channels = 3\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding='same', input_shape=(img_height, img_width, num_channels)),\n",
    "    MaxPooling2D(pool_size=(5, 5)),\n",
    "    Flatten(),\n",
    "    Dense(units=100, activation='relu'),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training parameters\n",
    "epochs = 20\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_datagen_instance,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_image_paths) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_datagen_instance, steps=test_datagen_instance.n // batch_size)\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "m4cmOojch_to",
    "gKiIShYiXv1C",
    "ydlq9_vRaUdQ",
    "yfxtbQ_2ZrWL"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
